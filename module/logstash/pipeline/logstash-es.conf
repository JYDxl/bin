input {
  file {
    path => "/extra/data/datax/log/2021-09-10/*.log"
    type => "datax"
    start_position => "beginning"
    #调试时使用，禁止sincedb_path记录已读取的位置，从而使每次读取都从头开始
    #    sincedb_path => "/dev/null"
    codec => multiline {
      pattern => "^%{TIMESTAMP_ISO8601}"
      what => "previous"
      negate => true
      charset => "UTF-8"
      auto_flush_interval => 2
    }
  }
}

filter {
  if "datax" == [type] {
    dissect {
      mapping => {
        #%{}中间不写名称表示忽略该值
        "path" => "%{}[%{job}]%{}"
        "message" => "%{time} %{+time} [%{thread}] %{level} %{class} - %{}"
      }
    }
    date {
      match => ["time","yyyy-MM-dd HH:mm:ss.SSS"]
    }
    mutate {
      strip => ["level","class"]
    }
    if "StandAloneJobContainerCommunicator" == [class] {
      clone {
        clones => ["datax-realtime"]
      }
    }
    if "datax-realtime" == [type] {
      dissect {
        mapping => {
          "message" => "%{} %{} [%{}] %{} %{} - Total takes %{totalTime}s | Total %{totalReadRecords} records, %{totalReadBytes} bytes | Speed %{bytesWriteSpeed}KB/s, %{recordWriteSpeed} records/s | Error %{errorRecords} records, %{errorBytes} bytes |  All Task WaitWriterTime %{allTaskWaitWriterTime}s |  All Task WaitReaderTime %{allTaskWaitReaderTime}s | Percentage %{percentage}%"
        }
      }
      mutate {
        remove_field => ["time","tags","message","host","level","class","path","thread"]
        convert => {
          "totalReadRecords" => "integer"
          "totalReadBytes" => "integer"
          "bytesWriteSpeed" => "float"
          "recordWriteSpeed" => "integer"
          "errorRecords" => "integer"
          "errorBytes" => "integer"
          "allTaskWaitWriterTime" => "float"
          "allTaskWaitReaderTime" => "float"
          "percentage" => "float"
          "totalTime" => "integer"
        }
      }
    }
    if "datax" == [type] {
      mutate {
        remove_field => ["time","tags"]
      }
    }
  }
}

#filter {
#  csv {
#    separator => ","
#    columns => ["id","content","genre"]
#  }
#
#  mutate {
#    split => {
#      "genre" => "|"
#    }
#    remove_field => ["path", "host","@timestamp","message"]
#  }
#
#  mutate {
#
#    split => ["content", "("]
#    add_field => {
#      "title" => "%{[content][0]}"
#    }
#    add_field => {
#      "year" => "%{[content][1]}"
#    }
#  }
#
#  mutate {
#    convert => {
#      "year" => "integer"
#    }
#    strip => ["title"]
#    remove_field => ["path", "host","@timestamp","message","content"]
#  }
#
#}

output {
  if "datax" == [type] {
    elasticsearch {
      hosts => ["http://elasticsearch-cluster1:9200", "http://elasticsearch-cluster2:9200", "http://elasticsearch-cluster3:9200"]
      index => "logs"
    }
    stdout {
    }
  }
  if "datax-realtime" == [type] {
    kafka {
      topic_id => "datax-realtime"
      bootstrap_servers => "kafka-cluster1:9092,kafka-cluster2:9093,kafka-cluster3:9094"
      codec => json {
      }
    }
    stdout {
    }
  }
}
