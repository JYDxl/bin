input {
  file {
    path => "/extra/data/datax/log/2021-09-07/*.log"
    type => "datax"
    start_position => "beginning"
    #调试时使用，禁止sincedb_path记录已读取的位置，从而使每次读取都从头开始
    #    sincedb_path => "/dev/null"
    codec => multiline {
      pattern => "^%{TIMESTAMP_ISO8601}"
      what => "previous"
      negate => true
      charset => "UTF-8"
      auto_flush_interval => 2
    }
  }
}

filter {
  if "datax" == [type] {
    dissect {
      mapping => {
        #%{}中间不写名称表示忽略该值
        "path" => "%{}[%{job}]%{}"
        "message" => "%{time} %{+time} [%{thread}] %{level} %{class} - %{}"
      }
    }
    date {
      match => ["time","yyyy-MM-dd HH:mm:ss.SSS"]
    }
    if "任务启动时刻" in [message] {
      clone {
        clones => ["datax,important"]
      }
    }
    mutate {
      remove_field => ["time","tags"]
      strip => ["level"]
    }
  }
}

#filter {
#  csv {
#    separator => ","
#    columns => ["id","content","genre"]
#  }
#
#  mutate {
#    split => {
#      "genre" => "|"
#    }
#    remove_field => ["path", "host","@timestamp","message"]
#  }
#
#  mutate {
#
#    split => ["content", "("]
#    add_field => {
#      "title" => "%{[content][0]}"
#    }
#    add_field => {
#      "year" => "%{[content][1]}"
#    }
#  }
#
#  mutate {
#    convert => {
#      "year" => "integer"
#    }
#    strip => ["title"]
#    remove_field => ["path", "host","@timestamp","message","content"]
#  }
#
#}

output {
  if "datax" == [type] {
    elasticsearch {
      hosts => ["http://elasticsearch-cluster1:9200", "http://elasticsearch-cluster2:9200", "http://elasticsearch-cluster3:9200"]
      index => "logs"
    }
  }
  if "datax,important" == [type] {
    stdout {
    }
  }
}
